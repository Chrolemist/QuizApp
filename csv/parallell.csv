Question;Options;Correct;Selected
En ogenomtänkt användning av delat minne (eng. Shared Memory) kan leda till problemet Race Condition som kan medföra att  _____ ?;Det multi-trådade programmet går betydligt långsammare än nödvändigt.|Parallell uppdatering av delad data blir inte korrekt så som det var tänkt.|Det kan uppstå korrupt data i slumpmässiga adresser i det delade minnet.|Alla trådar i programmet kraschar samtidigt vid åtkomst av delat minne.;Parallell uppdatering av delad data blir inte korrekt så som det var tänkt.;Parallell uppdatering av delad data blir inte korrekt så som det var tänkt.
Mekanismer för konstruktion av lås (eng. Mutual Exclusion) kan implementeras med hjälp av _______ ?;iv. Flaggor och semaforer (eng. Semaphores).|i. Skickande och mottagande av meddelanden (eng. Messsage Passing).|iii. Atomiska instruktioner (eng. Atomic Operations).|ii. Läsande och skrivande till ett antal delade variabler.;iii. Atomiska instruktioner (eng. Atomic Operations).;
Metoderna inom klassen Monitor inom namnrymden (eng. Namespace) System.Threading, används ofta tillsammans parvis som exempelvis _______ ?;iii. Monitor.Enter och Monitor.Pulse.|ii. Monitor.Wait och Monitor.PulseAll.|i. Monitor.Enter och Monitor.Exit.|iv. Monitor.Lock och Monitor.UnLock.;ii. Monitor.Wait och Monitor.PulseAll.|i. Monitor.Enter och Monitor.Exit.;
Loop-strukturer kan parallelliseras med hjälp av metoderna _____ inom namnrymden (eng. Namespace) System.Thread.Tasks ?;ii. Parallel.ForEach|i. Parallel.For|iv. Parallel.While|iii. Parallel.Repeat;ii. Parallel.ForEach|i. Parallel.For;
En huvudanledning till att det är nödvändigt att parallellisera program för att de skall kunna exekveras allt snabbare i framtiden är att  _____ ?;Processorernas kärnor blir inte signifikant mycket snabbare längre.|Antalet transistorer i en enskild mikroprocessor ökar med tiden.|De enskilda trådarnas minne annars inte räcker till hela programmet.|Strömförbrukningen ökar dramatiskt med högre klockfrekvenser.;Strömförbrukningen ökar dramatiskt med högre klockfrekvenser.|Processorernas kärnor blir inte signifikant mycket snabbare längre.;
Förutom att en abstrakt datatyp är trådsäker förväntas vanligtvis att den delade datastrukturen har egenskapen _______ sett till operationernas semantik?;iv. Concurrency.|i. Linearizability.|ii. Sequenceability.|iii. Consistency.;i. Linearizability.;
Non-Blocking Synchronization är en kategori av egenskaper och mekanismer för synkronisering, och kan delas in i underkategorierna _____ ?;iii. Wait-Free Synchronization.|i. Lock-Free Synchronization.|ii. Mutual-Exclusion Synchronization.|iv. Semaphore Synchronization.;iii. Wait-Free Synchronization.|i. Lock-Free Synchronization.;
Lås (eng. Mutual Exclusion) inbegriper och är nära relaterat till olika fenomen och begrepp som exempelvis  _______ ?;ii. Embarrising Parallelism.|i. High Processor Utilization.|iii. Deadlock.|iv. Race Condition.;iii. Deadlock.|iv. Race Condition.;
De olika principer för parallell programmering som stöds av ramverket Task Parallel Library (TPL) är _____ ?;i. Embarrasing Parallelism.|iv. Data Parallelism.|ii. Distributed Parallelism.|iii. Task Parallelism.;iii. Task Parallelism.|iv. Data Parallelism.;
För att inte begränsa den möjliga prestandan och skalbarheten för parallella program, är det viktigt att försöka minska antalet _______ ?;iv. Skrivningar till spridda adresser på delat minne.|iii. Operationer som använder lokalt minne.|ii. Atomiska instruktioner (eng. Atomic Operations).|i. Läsningar till spridda adresser på delat minne.;i. Läsningar till spridda adresser på delat minne.|iv. Skrivningar till spridda adresser på delat minne.|ii. Atomiska instruktioner (eng. Atomic Operations).;
En GPU (Graphics Processing Unit) lämpar sig bäst för utförandet av program och beräkningar med egenskapen/-erna ____ ?;iv. Synchronization-Heavy.|ii. Distributed Parallelism.|iii. Data Parallelism.|i. Task Parallelism.;iii. Data Parallelism.;
Begreppet ______ är relaterade till lokala system som använder fler än en typ av processorer eller processorkärnor som kan exekveras parallellt?;iii. Heterogeneous Computing.|iv. Patogeneous Computing.|ii. Homogeneous Computing.|i. Distributed Computing.;iii. Heterogeneous Computing.;
Trådar som exekveras inom ramverket CUDA har möjligheten/-erna att kunna ______ som inte är möjligt för vanliga parallella block?;ii. Kommunicera inbördes.|iv. Synkronisera inbördes.|iii. Använda matematiska operationer.|i. Modifiera innehåll i minne.;ii. Kommunicera inbördes.|iv. Synkronisera inbördes.;
För att säkerställa att alla trådar har passerat en viss kod-rad innan de går vidare, används i CUDA funktionen __syncthreads() som är en form av ______ ?;iv. Cache.|ii. Barrier.|iii. Memory.|i. Buffer.;ii. Barrier.;
Eftersom olika grafikkort kan ha olika arkitekturer och även andra egenskaper som skiljer dem emellan, så har CUDA indelat egenskaperna i grupper kallad ______ ?;iv. NVidia Power.|iii. Parallel Capability.|i. Processing Power.|ii. Compute Capability.;ii. Compute Capability.;
En specifik körande instans av en kernel som har startats på GPU med CUDA, kan ta reda på vilken global identitet som instansen har genom uttrycket  _____ ?;i. threadIdx.x + blockIdx.x * blockDim.x|iii. blockIdx.x + threadIdx.x * threadDim.x|ii. threadIdx.x + blockIdx.x * gridDim.x|iv. blockIdx.x + threadIdx.x * gridDim.x;i. threadIdx.x + blockIdx.x * blockDim.x;
Ramverket OpenCL ställer krav på att samtliga fysiska enheter som är kompatibla skall stödja beräkningar med egenskapen _____ ?;ii. Distributed Parallelism.|i. Task Parallelism|iii. Data Parallelism.|iv. Synchronization-Heavy.;iii. Data Parallelism.;
I normalfallet så behöver en körning av en kernel förberedas i OpenCL genom  ______ , som görs explicit i run-time i huvudprogrammet ?;iv. Uppvärmning av berörda beräkningskärnor (eng. Cores).|i. Kompilering av källkod|ii. Överföring av binärkod från Host till Device|iii. Kopiering av data från Host till Device;iii. Kopiering av data från Host till Device|i. Kompilering av källkod;
Minnestyperna ________ ingår som användbara inom ramverket OpenCL ?;i. Public memory|iii. Global memory|ii. Private memory|iv. Local memory;iv. Local memory|iii. Global memory|ii. Private memory;
Respektive arbetsenhets (eng. Work Item) unika ID sett till hela sessionen med arbetsenheter, fås fram genom den interna funktionen (eng. Intrinsic) _____ ?;i. get_local_id()|iii. get_total_id()|iv. get_thread_id()|ii. get_global_id();ii. get_global_id();
